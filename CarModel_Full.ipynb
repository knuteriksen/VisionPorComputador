{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CarModel_Full.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knuteriksen/VisionPorComputador/blob/main/CarModel_Full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPvMPRWUAydM"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUHtNrLZrvc3"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization as BN\n",
        "from keras.layers import GaussianNoise as GN\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.models import Model\n",
        "from keras.callbacks import LearningRateScheduler as LRS\n",
        "from keras.callbacks import Callback\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import os\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIO8o5JBNJ25"
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 20\n",
        "primary_epochs = 220\n",
        "secondary_epochs = 110"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdsa177ktfb6"
      },
      "source": [
        "# Download: ONLY ONCE!\n",
        "os.system('wget https://www.dropbox.com/s/sakfqp6o8pbgasm/data.tgz')\n",
        "os.system('tar xvzf data.tgz')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_J4RfaIM24h"
      },
      "source": [
        "def outer_product(x):\n",
        "  phi_I = tf.einsum('ijkm,ijkn->imn', x[0], x[1])\t\t# Einstein Notation  [batch,31,31,depth] x [batch,31,31,depth] -> [batch,depth,depth]\n",
        "  phi_I = tf.reshape(phi_I,[-1,512*512])\t          # Reshape from [batch_size,depth,depth] to [batch_size, depth*depth]\n",
        "  phi_I = tf.divide(phi_I,7*7)\t\t\t\t\t\t\t  \t  # Divide by feature map size [size * size]\n",
        "\n",
        "  y_ssqrt = tf.multiply(                            # Take signed square root of phi_I\n",
        "      tf.sign(phi_I),\n",
        "      tf.sqrt(tf.abs(phi_I)+1e-12)\n",
        "      )\n",
        "  \n",
        "  z_l2 = tf.nn.l2_normalize(y_ssqrt)\t\t\t\t\t\t\t  # Apply l2 normalization\n",
        "  \n",
        "  return z_l2\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  rotation_range=20,\n",
        "  zoom_range=[1.0,1.2],\n",
        "  horizontal_flip=True\n",
        "  )\n",
        "\n",
        "def multiple_data_generator(generator, X,Y,bs):\n",
        "    genX = generator.flow(X, Y, batch_size=bs)\n",
        "    while True:\n",
        "      [Xi,Yi] = genX.next()\n",
        "      yield [Xi,Xi],Yi\n",
        "\n",
        "def scheduler(epoch):\n",
        "    if epoch < primary_epochs*3/4:\n",
        "        return 0.1\n",
        "    else:\n",
        "        return 0.01\n",
        "    \n",
        "set_lr = LRS(scheduler)\n",
        "\n",
        "class PlotLearning(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        plt.rcParams[\"figure.figsize\"] = (15,10)\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.acc = []\n",
        "        self.val_acc = []\n",
        "        self.fig = plt.figure()\n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        plt.rcParams[\"figure.figsize\"] = (15,10)\n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.acc.append(logs.get('accuracy'))\n",
        "        self.val_acc.append(logs.get('val_accuracy'))\n",
        "        self.i += 1\n",
        "        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        ax1.set_yscale('log')\n",
        "        ax1.plot(self.x, self.losses, label=\"loss\")\n",
        "        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n",
        "        ax1.legend()\n",
        "        \n",
        "        ax2.plot(self.x, self.acc, label=\"accuracy\")\n",
        "        ax2.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
        "        ax2.legend()\n",
        "        \n",
        "        plt.show();\n",
        "        \n",
        "plot_callback = PlotLearning()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fzBUf87Hp2r"
      },
      "source": [
        "x_train = np.load('x_train.npy')\n",
        "x_test = np.load('x_test.npy')\n",
        "\n",
        "y_train = np.load('y_train.npy')\n",
        "y_test = np.load('y_test.npy')\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = y_train.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "y_train=y_train-1\n",
        "y_test=y_test-1\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = keras.applications.vgg16.preprocess_input(x_train)\n",
        "x_test = keras.applications.vgg16.preprocess_input(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3yKat8Ytivb"
      },
      "source": [
        "base_model_1 = VGG16(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=x_train.shape[1:]\n",
        ")\n",
        "\n",
        "for layer in base_model_1.layers:\n",
        "  layer._name = layer._name + str('_1')\n",
        "  layer.trainable = False;\n",
        "\n",
        "base_model_1.summary();\n",
        "\n",
        "\n",
        "base_model_2 = VGG16(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=x_train.shape[1:]\n",
        ")\n",
        "\n",
        "for layer in base_model_2.layers:\n",
        "  layer._name = layer._name + str('_2')\n",
        "  layer.trainable = False;\n",
        "\n",
        "base_model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojw44cOFuCiy"
      },
      "source": [
        "conv_1 = base_model_1.get_layer('block5_pool_1').output\n",
        "d1 = Dropout(0.5)(conv_1)\n",
        "\n",
        "conv_2 = base_model_2.get_layer('block5_pool_2').output\n",
        "d2 = Dropout(0.5)(conv_2)\n",
        "\n",
        "x = Lambda(outer_product, name='outer_product')([d1,d2])\n",
        "\n",
        "predictions=Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "model = Model(inputs=[base_model_1.input, base_model_2.input], outputs=predictions)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SRyAp1sQF0q"
      },
      "source": [
        "\n",
        "history1=model.fit(x=multiple_data_generator(datagen, x_train, y_train, batch_size),\n",
        "                  epochs=primary_epochs,\n",
        "                  steps_per_epoch = len(x_train) / batch_size,\n",
        "                  validation_data=([x_test, x_test], y_test),\n",
        "                  verbose=1\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drzE8smu0I_J"
      },
      "source": [
        "for layer in base_model_1.layers:\n",
        "  layer.trainable = True\n",
        "\n",
        "for layer in base_model_2.layers:\n",
        "  layer.trainable = True\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.00001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1JCCYecQjgj"
      },
      "source": [
        "\n",
        "history2=model.fit(x=multiple_data_generator(datagen, x_train, y_train, batch_size),\n",
        "                  epochs=secondary_epochs,\n",
        "                  steps_per_epoch = len(x_train) / batch_size,                 \n",
        "                  validation_data=([x_test, x_test], y_test),\n",
        "                  verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj6EupSmII0m"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
        "ax1.set_yscale('log')\n",
        "ax1.plot(history1.history['loss'], label=\"loss\")\n",
        "ax1.plot(history1.history['val_loss'], label=\"val_loss\")\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(history1.history['accuracy'], label=\"accuracy\")\n",
        "ax2.plot(history1.history['val_accuracy'], label=\"validation accuracy\")\n",
        "ax2.legend()\n",
        "\n",
        "plt.setp(ax1, xlabel='Epochs')\n",
        "plt.setp(ax2, xlabel='Epochs')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TbicvP7IOc0"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
        "ax1.set_yscale('log')\n",
        "ax1.plot(history2.history['loss'], label=\"loss\")\n",
        "ax1.plot(history2.history['val_loss'], label=\"val_loss\")\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(history2.history['accuracy'], label=\"accuracy\")\n",
        "ax2.plot(history2.history['val_accuracy'], label=\"validation accuracy\")\n",
        "ax2.legend()\n",
        "\n",
        "plt.setp(ax1, xlabel='Epochs')\n",
        "plt.setp(ax2, xlabel='Epochs')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}